Welcome to Dbrief.AI!

## Set up Process

1) Create a virtual env `virtualenv ~/eb-new`
2) Activate by running `source ~/eb-new/bin/activate`
3) Clone repository and install `brew install git-lfs`
4) Import all the requirements from requirements.txt through `pip install -r requirements.txt`
5) Run `python manage.py runserver`
6) Install / set up docker
7) Pull the elastic search docker image (commands included in the elastic search section)
8) Install mysql and create a password
9) Update the password in settings.py
10) Run the migrate commands


## Testing Process
We currently set up a few different directories for tests including repositories and handlers.  The repository tests check the read / write operations with the database and the view tests make calls directly to the /endpoint and check that it runs with a 200 response.  All databases can be pre populated using a fixtures file which includes dummy data and is loaded into the db prior to running the tests. An example can be found in articleRec/fixtures.  In order to run all of the tests, run ```./manage.py test```. In order to run tests in a particular directory, run ```./manage.py rest topicModeling``` for example.


## Link to Documentation
This document consists of a running


## Logging
We currently use logtail for all logging purposes from our production system. Please log into in order to access the logs.


## Deployment to AWS
Deployment to AWS is a 2 step process - you can


## Mysql Migration


## Checking prod Mysql


## Elastic Search
In order to set up elastic search on docker you need to run the following commands -
1. ```sudo systemctl start docker```
2. ```sudo docker pull docker.elastic.co/elasticsearch/elasticsearch:7.9.2```
3. ```sudo docker run -d -p 9200:9200 -e 'discovery.type=single-node' elasticsearch:7.9.2```

